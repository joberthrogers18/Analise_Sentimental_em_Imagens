{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from pickle import dump, load\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0716f0505f18472994a55e62340089a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.merge import add\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# library to see the progress during the training\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_images = '/tf/notebooks/captioning_image/Flicker8k_Dataset'\n",
    "dataset_text = '/tf/notebooks/captioning_image/Flickr8k_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# get all images and your respective captions\n",
    "def all_img_captions(filename):\n",
    "    file = load_doc(filename)\n",
    "    captions = file.split('\\n')\n",
    "    descriptions = {}\n",
    "    for caption in captions[:-1]:\n",
    "        img, caption = caption.split('\\t')\n",
    "        if img[:-2] not in descriptions:\n",
    "            descriptions[img[:-2]] = [caption]\n",
    "        else:\n",
    "            descriptions[img[:-2]].append(caption)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da descrição =  8092\n",
      "Tamanho do vocabulario =  8763\n"
     ]
    }
   ],
   "source": [
    "def cleaning_text(captions):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for img, caps in captions.items():\n",
    "        for i, img_caption in enumerate(caps):\n",
    "            \n",
    "            img_caption.replace(\"-\", \" \")\n",
    "            desc = img_caption.split()\n",
    "            \n",
    "            # convert lowercase\n",
    "            desc = [word.lower() for word in desc]\n",
    "            # remove punctuation from words\n",
    "            desc = [word.translate(table) for word in desc]\n",
    "            # remove articles\n",
    "            desc = [word for word in desc if(len(word) > 1)]\n",
    "            # remove token with numbers\n",
    "            desc = [word for word in desc if(word.isalpha())]\n",
    "            \n",
    "            # convert to a string again\n",
    "            img_caption = ' '.join(desc)\n",
    "            captions[img][i] = img_caption\n",
    "    return captions\n",
    "\n",
    "def text_vocabulary(descriptions):\n",
    "    # build vocabulary of all unique words\n",
    "    vocab = set()\n",
    "    \n",
    "    for key in descriptions.keys():\n",
    "        [vocab.update(d.split()) for d in descriptions[key]]\n",
    "        \n",
    "    return vocab\n",
    "\n",
    "def save_descriptions(descriptions, filename):\n",
    "    lines = list()\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key + '\\t' + desc)\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "    \n",
    "dataset_images = '/tf/notebooks/captioning_image/Flicker8k_Dataset'\n",
    "dataset_text = '/tf/notebooks/captioning_image/Flickr8k_text'\n",
    "\n",
    "filename = dataset_text + '/Flickr8k.token.txt'\n",
    "\n",
    "descriptions = all_img_captions(filename)\n",
    "print('Tamanho da descrição = ', len(descriptions))\n",
    "\n",
    "# cleaning the description\n",
    "clean_descriptions = cleaning_text(descriptions)\n",
    "\n",
    "# building vocabulary\n",
    "vocabulary = text_vocabulary(clean_descriptions)\n",
    "print('Tamanho do vocabulario = ', len(vocabulary))\n",
    "\n",
    "save_descriptions(clean_descriptions, 'descriptions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZED_IMAGE_NUMBER = 224\n",
    "\n",
    "def extract_features(directory):\n",
    "    model = ResNet50(include_top=False, pooling='avg')\n",
    "    features = {}\n",
    "    \n",
    "    for img in tqdm(os.listdir(directory)):\n",
    "        filename = f\"{directory}/{img}\"\n",
    "        image = Image.open(filename)\n",
    "        image = image.resize((RESIZED_IMAGE_NUMBER, RESIZED_IMAGE_NUMBER))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        # image = preprocess_input(image)\n",
    "        image = image / 127.5\n",
    "        image = image - 1.0\n",
    "        \n",
    "        feature = model.predict(image)\n",
    "        features[img] = feature\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61389855d3b744c4991b15d215157dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_features = extract_features(dataset_images)\n",
    "dump(current_features, open(\"features.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = load(open('features.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_photos(filename):\n",
    "    file = load_doc(filename)\n",
    "    photos = file.split('\\n')[:-1]\n",
    "    return photos\n",
    "\n",
    "def load_clean_descriptions(filename, photos):\n",
    "    file = load_doc(filename)\n",
    "    descriptions = {}\n",
    "    \n",
    "    for line in file.split('\\n'):\n",
    "        words = line.split()\n",
    "        \n",
    "        if len(words) < 1:\n",
    "            continue\n",
    "            \n",
    "        image, image_caption = words[0], words[1:]\n",
    "        \n",
    "        if image in photos:\n",
    "            if image not in descriptions:\n",
    "                descriptions[image] = []\n",
    "            desc = '<start> ' + \" \".join(image_caption) + ' <end>'\n",
    "            descriptions[image].append(desc)\n",
    "    return descriptions\n",
    "\n",
    "def load_features(photos):\n",
    "    \n",
    "    all_features = load(open('features.p', 'rb'))\n",
    "    features = {k:all_features[k] for k in photos}\n",
    "    return features\n",
    "    \n",
    "filename = f'{dataset_text}/Flickr_8k.trainImages.txt'\n",
    "\n",
    "train_imgs = load_photos(filename)\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt', train_imgs)\n",
    "train_features = load_features(train_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_list(descriptions):\n",
    "    all_desc = []\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.append(d) for d in descriptions[key]]\n",
    "    return all_desc\n",
    "\n",
    "def create_tokenizer(descriptions):\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(desc_list)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7577"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "dump(tokenizer, open('tokenizer.p', 'wb'))\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end': 1,\n",
       " 'start': 2,\n",
       " 'in': 3,\n",
       " 'the': 4,\n",
       " 'on': 5,\n",
       " 'is': 6,\n",
       " 'and': 7,\n",
       " 'dog': 8,\n",
       " 'with': 9,\n",
       " 'man': 10,\n",
       " 'of': 11,\n",
       " 'two': 12,\n",
       " 'white': 13,\n",
       " 'black': 14,\n",
       " 'boy': 15,\n",
       " 'are': 16,\n",
       " 'woman': 17,\n",
       " 'girl': 18,\n",
       " 'to': 19,\n",
       " 'wearing': 20,\n",
       " 'at': 21,\n",
       " 'people': 22,\n",
       " 'water': 23,\n",
       " 'brown': 24,\n",
       " 'young': 25,\n",
       " 'red': 26,\n",
       " 'an': 27,\n",
       " 'his': 28,\n",
       " 'blue': 29,\n",
       " 'dogs': 30,\n",
       " 'running': 31,\n",
       " 'through': 32,\n",
       " 'playing': 33,\n",
       " 'while': 34,\n",
       " 'down': 35,\n",
       " 'shirt': 36,\n",
       " 'ball': 37,\n",
       " 'standing': 38,\n",
       " 'little': 39,\n",
       " 'grass': 40,\n",
       " 'snow': 41,\n",
       " 'child': 42,\n",
       " 'person': 43,\n",
       " 'jumping': 44,\n",
       " 'over': 45,\n",
       " 'three': 46,\n",
       " 'sitting': 47,\n",
       " 'front': 48,\n",
       " 'field': 49,\n",
       " 'holding': 50,\n",
       " 'small': 51,\n",
       " 'yellow': 52,\n",
       " 'green': 53,\n",
       " 'group': 54,\n",
       " 'up': 55,\n",
       " 'by': 56,\n",
       " 'large': 57,\n",
       " 'one': 58,\n",
       " 'walking': 59,\n",
       " 'her': 60,\n",
       " 'men': 61,\n",
       " 'children': 62,\n",
       " 'air': 63,\n",
       " 'into': 64,\n",
       " 'near': 65,\n",
       " 'mouth': 66,\n",
       " 'beach': 67,\n",
       " 'jumps': 68,\n",
       " 'runs': 69,\n",
       " 'another': 70,\n",
       " 'for': 71,\n",
       " 'street': 72,\n",
       " 'from': 73,\n",
       " 'its': 74,\n",
       " 'riding': 75,\n",
       " 'stands': 76,\n",
       " 'bike': 77,\n",
       " 'girls': 78,\n",
       " 'as': 79,\n",
       " 'outside': 80,\n",
       " 'play': 81,\n",
       " 'rock': 82,\n",
       " 'other': 83,\n",
       " 'looking': 84,\n",
       " 'orange': 85,\n",
       " 'out': 86,\n",
       " 'pink': 87,\n",
       " 'player': 88,\n",
       " 'next': 89,\n",
       " 'off': 90,\n",
       " 'camera': 91,\n",
       " 'pool': 92,\n",
       " 'their': 93,\n",
       " 'jacket': 94,\n",
       " 'hat': 95,\n",
       " 'behind': 96,\n",
       " 'around': 97,\n",
       " 'boys': 98,\n",
       " 'women': 99,\n",
       " 'toy': 100,\n",
       " 'soccer': 101,\n",
       " 'some': 102,\n",
       " 'wall': 103,\n",
       " 'sits': 104,\n",
       " 'background': 105,\n",
       " 'has': 106,\n",
       " 'dressed': 107,\n",
       " 'walks': 108,\n",
       " 'dirt': 109,\n",
       " 'plays': 110,\n",
       " 'mountain': 111,\n",
       " 'stand': 112,\n",
       " 'along': 113,\n",
       " 'park': 114,\n",
       " 'top': 115,\n",
       " 'football': 116,\n",
       " 'climbing': 117,\n",
       " 'building': 118,\n",
       " 'looks': 119,\n",
       " 'face': 120,\n",
       " 'stick': 121,\n",
       " 'four': 122,\n",
       " 'smiling': 123,\n",
       " 'grassy': 124,\n",
       " 'crowd': 125,\n",
       " 'across': 126,\n",
       " 'swimming': 127,\n",
       " 'carrying': 128,\n",
       " 'hill': 129,\n",
       " 'sand': 130,\n",
       " 'rides': 131,\n",
       " 'skateboard': 132,\n",
       " 'tree': 133,\n",
       " 'holds': 134,\n",
       " 'baby': 135,\n",
       " 'car': 136,\n",
       " 'each': 137,\n",
       " 'snowy': 138,\n",
       " 'tennis': 139,\n",
       " 'hair': 140,\n",
       " 'together': 141,\n",
       " 'ocean': 142,\n",
       " 'picture': 143,\n",
       " 'doing': 144,\n",
       " 'tan': 145,\n",
       " 'road': 146,\n",
       " 'race': 147,\n",
       " 'him': 148,\n",
       " 'jump': 149,\n",
       " 'area': 150,\n",
       " 'that': 151,\n",
       " 'bench': 152,\n",
       " 'bicycle': 153,\n",
       " 'it': 154,\n",
       " 'helmet': 155,\n",
       " 'trick': 156,\n",
       " 'sidewalk': 157,\n",
       " 'back': 158,\n",
       " 'sit': 159,\n",
       " 'shorts': 160,\n",
       " 'game': 161,\n",
       " 'run': 162,\n",
       " 'ground': 163,\n",
       " 'catch': 164,\n",
       " 'basketball': 165,\n",
       " 'fence': 166,\n",
       " 'head': 167,\n",
       " 'swing': 168,\n",
       " 'dress': 169,\n",
       " 'kids': 170,\n",
       " 'hand': 171,\n",
       " 'something': 172,\n",
       " 'being': 173,\n",
       " 'purple': 174,\n",
       " 'frisbee': 175,\n",
       " 'slide': 176,\n",
       " 'skateboarder': 177,\n",
       " 'several': 178,\n",
       " 'lake': 179,\n",
       " 'wave': 180,\n",
       " 'covered': 181,\n",
       " 'there': 182,\n",
       " 'city': 183,\n",
       " 'walk': 184,\n",
       " 'ramp': 185,\n",
       " 'path': 186,\n",
       " 'side': 187,\n",
       " 'track': 188,\n",
       " 'players': 189,\n",
       " 'posing': 190,\n",
       " 'baseball': 191,\n",
       " 'big': 192,\n",
       " 'long': 193,\n",
       " 'high': 194,\n",
       " 'wooden': 195,\n",
       " 'coat': 196,\n",
       " 'watches': 197,\n",
       " 'pants': 198,\n",
       " 'boat': 199,\n",
       " 'arms': 200,\n",
       " 'ride': 201,\n",
       " 'trees': 202,\n",
       " 'them': 203,\n",
       " 'horse': 204,\n",
       " 'rocky': 205,\n",
       " 'watching': 206,\n",
       " 'couple': 207,\n",
       " 'motorcycle': 208,\n",
       " 'uniform': 209,\n",
       " 'rope': 210,\n",
       " 'rocks': 211,\n",
       " 'under': 212,\n",
       " 'look': 213,\n",
       " 'grey': 214,\n",
       " 'sunglasses': 215,\n",
       " 'suit': 216,\n",
       " 'hands': 217,\n",
       " 'dark': 218,\n",
       " 'racing': 219,\n",
       " 'watch': 220,\n",
       " 'sign': 221,\n",
       " 'jeans': 222,\n",
       " 'older': 223,\n",
       " 'towards': 224,\n",
       " 'guy': 225,\n",
       " 'beside': 226,\n",
       " 'table': 227,\n",
       " 'does': 228,\n",
       " 'pose': 229,\n",
       " 'snowboarder': 230,\n",
       " 'lady': 231,\n",
       " 'above': 232,\n",
       " 'who': 233,\n",
       " 'ice': 234,\n",
       " 'river': 235,\n",
       " 'colorful': 236,\n",
       " 'yard': 237,\n",
       " 'striped': 238,\n",
       " 'cliff': 239,\n",
       " 'onto': 240,\n",
       " 'woods': 241,\n",
       " 'against': 242,\n",
       " 'taking': 243,\n",
       " 'open': 244,\n",
       " 'he': 245,\n",
       " 'midair': 246,\n",
       " 'asian': 247,\n",
       " 'blonde': 248,\n",
       " 'bird': 249,\n",
       " 'mountains': 250,\n",
       " 'leaps': 251,\n",
       " 'after': 252,\n",
       " 'climbs': 253,\n",
       " 'blond': 254,\n",
       " 'chasing': 255,\n",
       " 'hockey': 256,\n",
       " 'rider': 257,\n",
       " 'body': 258,\n",
       " 'laying': 259,\n",
       " 'inside': 260,\n",
       " 'cap': 261,\n",
       " 'smiles': 262,\n",
       " 'glasses': 263,\n",
       " 'kid': 264,\n",
       " 'during': 265,\n",
       " 'collar': 266,\n",
       " 'many': 267,\n",
       " 'surrounded': 268,\n",
       " 'wet': 269,\n",
       " 'old': 270,\n",
       " 'skier': 271,\n",
       " 'colored': 272,\n",
       " 'edge': 273,\n",
       " 'very': 274,\n",
       " 'fountain': 275,\n",
       " 'playground': 276,\n",
       " 'performing': 277,\n",
       " 'forest': 278,\n",
       " 'hanging': 279,\n",
       " 'five': 280,\n",
       " 'backpack': 281,\n",
       " 'takes': 282,\n",
       " 'others': 283,\n",
       " 'surfer': 284,\n",
       " 'outdoors': 285,\n",
       " 'tshirt': 286,\n",
       " 'whilst': 287,\n",
       " 'toddler': 288,\n",
       " 'night': 289,\n",
       " 'object': 290,\n",
       " 'biker': 291,\n",
       " 'trying': 292,\n",
       " 'team': 293,\n",
       " 'brick': 294,\n",
       " 'away': 295,\n",
       " 'guitar': 296,\n",
       " 'past': 297,\n",
       " 'talking': 298,\n",
       " 'pole': 299,\n",
       " 'making': 300,\n",
       " 'surfboard': 301,\n",
       " 'light': 302,\n",
       " 'middle': 303,\n",
       " 'arm': 304,\n",
       " 'gray': 305,\n",
       " 'shore': 306,\n",
       " 'this': 307,\n",
       " 'bed': 308,\n",
       " 'flying': 309,\n",
       " 'window': 310,\n",
       " 'eating': 311,\n",
       " 'haired': 312,\n",
       " 'going': 313,\n",
       " 'carries': 314,\n",
       " 'someone': 315,\n",
       " 'about': 316,\n",
       " 'trail': 317,\n",
       " 'toward': 318,\n",
       " 'line': 319,\n",
       " 'tall': 320,\n",
       " 'flowers': 321,\n",
       " 'outfit': 322,\n",
       " 'clothes': 323,\n",
       " 'dancing': 324,\n",
       " 'leash': 325,\n",
       " 'course': 326,\n",
       " 'sky': 327,\n",
       " 'swinging': 328,\n",
       " 'nearby': 329,\n",
       " 'bridge': 330,\n",
       " 'plastic': 331,\n",
       " 'stone': 332,\n",
       " 'bag': 333,\n",
       " 'steps': 334,\n",
       " 'leaping': 335,\n",
       " 'sliding': 336,\n",
       " 'poses': 337,\n",
       " 'floor': 338,\n",
       " 'shallow': 339,\n",
       " 'between': 340,\n",
       " 'fighting': 341,\n",
       " 'ready': 342,\n",
       " 'catches': 343,\n",
       " 'gear': 344,\n",
       " 'waves': 345,\n",
       " 'legs': 346,\n",
       " 'shirts': 347,\n",
       " 'splashing': 348,\n",
       " 'all': 349,\n",
       " 'bright': 350,\n",
       " 'climber': 351,\n",
       " 'room': 352,\n",
       " 'costume': 353,\n",
       " 'house': 354,\n",
       " 'skateboarding': 355,\n",
       " 'tongue': 356,\n",
       " 'board': 357,\n",
       " 'obstacle': 358,\n",
       " 'chair': 359,\n",
       " 'day': 360,\n",
       " 'sandy': 361,\n",
       " 'swings': 362,\n",
       " 'lawn': 363,\n",
       " 'they': 364,\n",
       " 'clothing': 365,\n",
       " 'leaves': 366,\n",
       " 'mud': 367,\n",
       " 'metal': 368,\n",
       " 'get': 369,\n",
       " 'railing': 370,\n",
       " 'golden': 371,\n",
       " 'jersey': 372,\n",
       " 'outdoor': 373,\n",
       " 'winter': 374,\n",
       " 'wears': 375,\n",
       " 'smile': 376,\n",
       " 'male': 377,\n",
       " 'store': 378,\n",
       " 'adults': 379,\n",
       " 'lot': 380,\n",
       " 'getting': 381,\n",
       " 'drink': 382,\n",
       " 'adult': 383,\n",
       " 'drinking': 384,\n",
       " 'sun': 385,\n",
       " 'female': 386,\n",
       " 'skiing': 387,\n",
       " 'sled': 388,\n",
       " 'gets': 389,\n",
       " 'waiting': 390,\n",
       " 'bar': 391,\n",
       " 'concrete': 392,\n",
       " 'set': 393,\n",
       " 'stairs': 394,\n",
       " 'catching': 395,\n",
       " 'overlooking': 396,\n",
       " 'uniforms': 397,\n",
       " 'trampoline': 398,\n",
       " 'rail': 399,\n",
       " 'bathing': 400,\n",
       " 'sweater': 401,\n",
       " 'wooded': 402,\n",
       " 'leaning': 403,\n",
       " 'makes': 404,\n",
       " 'distance': 405,\n",
       " 'horses': 406,\n",
       " 'pulling': 407,\n",
       " 'train': 408,\n",
       " 'fire': 409,\n",
       " 'swims': 410,\n",
       " 'laughing': 411,\n",
       " 'huge': 412,\n",
       " 'chases': 413,\n",
       " 'hats': 414,\n",
       " 'number': 415,\n",
       " 'fishing': 416,\n",
       " 'busy': 417,\n",
       " 'throwing': 418,\n",
       " 'eyes': 419,\n",
       " 'tricks': 420,\n",
       " 'cellphone': 421,\n",
       " 'shirtless': 422,\n",
       " 'animal': 423,\n",
       " 'umbrella': 424,\n",
       " 'flies': 425,\n",
       " 'puppy': 426,\n",
       " 'tries': 427,\n",
       " 'performs': 428,\n",
       " 'hold': 429,\n",
       " 'vest': 430,\n",
       " 'stream': 431,\n",
       " 'nose': 432,\n",
       " 'swim': 433,\n",
       " 'hurdle': 434,\n",
       " 'puddle': 435,\n",
       " 'pond': 436,\n",
       " 'bubbles': 437,\n",
       " 'snowboard': 438,\n",
       " 'life': 439,\n",
       " 'view': 440,\n",
       " 'deep': 441,\n",
       " 'elderly': 442,\n",
       " 'lying': 443,\n",
       " 'surfing': 444,\n",
       " 'upside': 445,\n",
       " 'climb': 446,\n",
       " 'wetsuit': 447,\n",
       " 'food': 448,\n",
       " 'tank': 449,\n",
       " 'ski': 450,\n",
       " 'muddy': 451,\n",
       " 'guys': 452,\n",
       " 'hiker': 453,\n",
       " 'american': 454,\n",
       " 'trunks': 455,\n",
       " 'reading': 456,\n",
       " 'take': 457,\n",
       " 'dry': 458,\n",
       " 'or': 459,\n",
       " 'photo': 460,\n",
       " 'tire': 461,\n",
       " 'no': 462,\n",
       " 'feet': 463,\n",
       " 'both': 464,\n",
       " 'truck': 465,\n",
       " 'flag': 466,\n",
       " 'slides': 467,\n",
       " 'bat': 468,\n",
       " 'left': 469,\n",
       " 'equipment': 470,\n",
       " 'bags': 471,\n",
       " 'slope': 472,\n",
       " 'court': 473,\n",
       " 'surf': 474,\n",
       " 'shoes': 475,\n",
       " 'flip': 476,\n",
       " 'right': 477,\n",
       " 'dresses': 478,\n",
       " 'like': 479,\n",
       " 'turn': 480,\n",
       " 'ledge': 481,\n",
       " 'harness': 482,\n",
       " 'vehicle': 483,\n",
       " 'she': 484,\n",
       " 'mask': 485,\n",
       " 'shopping': 486,\n",
       " 'couch': 487,\n",
       " 'flags': 488,\n",
       " 'coming': 489,\n",
       " 'greyhound': 490,\n",
       " 'book': 491,\n",
       " 'bikes': 492,\n",
       " 'dock': 493,\n",
       " 'skirt': 494,\n",
       " 'be': 495,\n",
       " 'falling': 496,\n",
       " 'waterfall': 497,\n",
       " 'structure': 498,\n",
       " 'raft': 499,\n",
       " 'stunt': 500,\n",
       " 'biting': 501,\n",
       " 'lone': 502,\n",
       " 'subway': 503,\n",
       " 'cement': 504,\n",
       " 'cigarette': 505,\n",
       " 'skis': 506,\n",
       " 'setting': 507,\n",
       " 'fight': 508,\n",
       " 'parking': 509,\n",
       " 'parade': 510,\n",
       " 'restaurant': 511,\n",
       " 'inflatable': 512,\n",
       " 'cart': 513,\n",
       " 'paper': 514,\n",
       " 'closeup': 515,\n",
       " 'ears': 516,\n",
       " 'tent': 517,\n",
       " 'faces': 518,\n",
       " 'sweatshirt': 519,\n",
       " 'hiking': 520,\n",
       " 'skating': 521,\n",
       " 'airborne': 522,\n",
       " 'bus': 523,\n",
       " 'family': 524,\n",
       " 'kicking': 525,\n",
       " 'driving': 526,\n",
       " 'chairs': 527,\n",
       " 'hit': 528,\n",
       " 'scarf': 529,\n",
       " 'goal': 530,\n",
       " 'kayak': 531,\n",
       " 'low': 532,\n",
       " 'ring': 533,\n",
       " 'tunnel': 534,\n",
       " 'goggles': 535,\n",
       " 'german': 536,\n",
       " 'goes': 537,\n",
       " 'crowded': 538,\n",
       " 'using': 539,\n",
       " 'short': 540,\n",
       " 'shepherd': 541,\n",
       " 'fallen': 542,\n",
       " 'cars': 543,\n",
       " 'canoe': 544,\n",
       " 'wheel': 545,\n",
       " 'hugging': 546,\n",
       " 'blanket': 547,\n",
       " 'bald': 548,\n",
       " 'dance': 549,\n",
       " 'kick': 550,\n",
       " 'pictures': 551,\n",
       " 'jackets': 552,\n",
       " 'have': 553,\n",
       " 'pushing': 554,\n",
       " 'pile': 555,\n",
       " 'cyclist': 556,\n",
       " 'silver': 557,\n",
       " 'six': 558,\n",
       " 'boots': 559,\n",
       " 'painted': 560,\n",
       " 'held': 561,\n",
       " 'splashes': 562,\n",
       " 'glass': 563,\n",
       " 'bmx': 564,\n",
       " 'wood': 565,\n",
       " 'drinks': 566,\n",
       " 'gold': 567,\n",
       " 'sunset': 568,\n",
       " 'throws': 569,\n",
       " 'smaller': 570,\n",
       " 'backyard': 571,\n",
       " 'skate': 572,\n",
       " 'kicks': 573,\n",
       " 'leather': 574,\n",
       " 'garden': 575,\n",
       " 'surface': 576,\n",
       " 'event': 577,\n",
       " 'stuffed': 578,\n",
       " 'bottle': 579,\n",
       " 'hangs': 580,\n",
       " 'volleyball': 581,\n",
       " 'beard': 582,\n",
       " 'blowing': 583,\n",
       " 'microphone': 584,\n",
       " 'shaking': 585,\n",
       " 'statue': 586,\n",
       " 'diving': 587,\n",
       " 'door': 588,\n",
       " 'teenage': 589,\n",
       " 'bicyclist': 590,\n",
       " 'band': 591,\n",
       " 'fluffy': 592,\n",
       " 'piece': 593,\n",
       " 'smoking': 594,\n",
       " 'party': 595,\n",
       " 'corner': 596,\n",
       " 'few': 597,\n",
       " 'sports': 598,\n",
       " 'bikini': 599,\n",
       " 'rugby': 600,\n",
       " 'net': 601,\n",
       " 'below': 602,\n",
       " 'sticking': 603,\n",
       " 'underwater': 604,\n",
       " 'scooter': 605,\n",
       " 'furry': 606,\n",
       " 'sunny': 607,\n",
       " 'balls': 608,\n",
       " 'outfits': 609,\n",
       " 'graffiti': 610,\n",
       " 'paint': 611,\n",
       " 'sleeping': 612,\n",
       " 'prepares': 613,\n",
       " 'buildings': 614,\n",
       " 'bicycles': 615,\n",
       " 'gathered': 616,\n",
       " 'suits': 617,\n",
       " 'hind': 618,\n",
       " 'snowboarding': 619,\n",
       " 'full': 620,\n",
       " 'staring': 621,\n",
       " 'lays': 622,\n",
       " 'sticks': 623,\n",
       " 'same': 624,\n",
       " 'wrestle': 625,\n",
       " 'attempts': 626,\n",
       " 'leg': 627,\n",
       " 'wrestling': 628,\n",
       " 'racetrack': 629,\n",
       " 'bunch': 630,\n",
       " 'costumes': 631,\n",
       " 'log': 632,\n",
       " 'crossing': 633,\n",
       " 'phone': 634,\n",
       " 'cup': 635,\n",
       " 'poles': 636,\n",
       " 'motorcyclist': 637,\n",
       " 'bride': 638,\n",
       " 'way': 639,\n",
       " 'steep': 640,\n",
       " 'attached': 641,\n",
       " 'clear': 642,\n",
       " 'dances': 643,\n",
       " 'flower': 644,\n",
       " 'go': 645,\n",
       " 'spectators': 646,\n",
       " 'throw': 647,\n",
       " 'plaid': 648,\n",
       " 'shot': 649,\n",
       " 'do': 650,\n",
       " 'cat': 651,\n",
       " 'show': 652,\n",
       " 'beer': 653,\n",
       " 'sprinkler': 654,\n",
       " 'make': 655,\n",
       " 'fast': 656,\n",
       " 'display': 657,\n",
       " 'wide': 658,\n",
       " 'pointing': 659,\n",
       " 'teams': 660,\n",
       " 'box': 661,\n",
       " 'kitchen': 662,\n",
       " 'desert': 663,\n",
       " 'pavement': 664,\n",
       " 'swimsuit': 665,\n",
       " 'just': 666,\n",
       " 'talks': 667,\n",
       " 'gym': 668,\n",
       " 'bearded': 669,\n",
       " 'kissing': 670,\n",
       " 'beige': 671,\n",
       " 'tube': 672,\n",
       " 'mohawk': 673,\n",
       " 'branch': 674,\n",
       " 'stage': 675,\n",
       " 'greyhounds': 676,\n",
       " 'racket': 677,\n",
       " 'which': 678,\n",
       " 'leans': 679,\n",
       " 'attempting': 680,\n",
       " 'wear': 681,\n",
       " 'police': 682,\n",
       " 'shop': 683,\n",
       " 'skateboards': 684,\n",
       " 'bull': 685,\n",
       " 'santa': 686,\n",
       " 'competition': 687,\n",
       " 'paved': 688,\n",
       " 'facing': 689,\n",
       " 'seat': 690,\n",
       " 'traffic': 691,\n",
       " 'sheep': 692,\n",
       " 'heads': 693,\n",
       " 'headphones': 694,\n",
       " 'hits': 695,\n",
       " 'toys': 696,\n",
       " 'carpet': 697,\n",
       " 'racer': 698,\n",
       " 'fish': 699,\n",
       " 'cowboy': 700,\n",
       " 'points': 701,\n",
       " 'teeth': 702,\n",
       " 'rain': 703,\n",
       " 'hoop': 704,\n",
       " 'cow': 705,\n",
       " 'waving': 706,\n",
       " 'pushes': 707,\n",
       " 'hose': 708,\n",
       " 'hole': 709,\n",
       " 'platform': 710,\n",
       " 'snowcovered': 711,\n",
       " 'unicycle': 712,\n",
       " 'ladies': 713,\n",
       " 'drives': 714,\n",
       " 'shoulder': 715,\n",
       " 'dirty': 716,\n",
       " 'barefoot': 717,\n",
       " 'bucket': 718,\n",
       " 'gravel': 719,\n",
       " 'chewing': 720,\n",
       " 'fenced': 721,\n",
       " 'cream': 722,\n",
       " 'headband': 723,\n",
       " 'birds': 724,\n",
       " 'wedding': 725,\n",
       " 'reads': 726,\n",
       " 'onlookers': 727,\n",
       " 'eats': 728,\n",
       " 'close': 729,\n",
       " 'rough': 730,\n",
       " 'puppies': 731,\n",
       " 'bottom': 732,\n",
       " 'wading': 733,\n",
       " 'downhill': 734,\n",
       " 'rural': 735,\n",
       " 'public': 736,\n",
       " 'splash': 737,\n",
       " 'cross': 738,\n",
       " 'motocross': 739,\n",
       " 'waits': 740,\n",
       " 'showing': 741,\n",
       " 'bars': 742,\n",
       " 'balloon': 743,\n",
       " 'goalie': 744,\n",
       " 'match': 745,\n",
       " 'bubble': 746,\n",
       " 'can': 747,\n",
       " 'boats': 748,\n",
       " 'landscape': 749,\n",
       " 'resting': 750,\n",
       " 'video': 751,\n",
       " 'parked': 752,\n",
       " 'wait': 753,\n",
       " 'purse': 754,\n",
       " 'wire': 755,\n",
       " 'fall': 756,\n",
       " 'younger': 757,\n",
       " 'scene': 758,\n",
       " 'retriever': 759,\n",
       " 'amusement': 760,\n",
       " 'among': 761,\n",
       " 'urban': 762,\n",
       " 'painting': 763,\n",
       " 'ropes': 764,\n",
       " 'art': 765,\n",
       " 'beautiful': 766,\n",
       " 'helmets': 767,\n",
       " 'empty': 768,\n",
       " 'where': 769,\n",
       " 'foot': 770,\n",
       " 'seated': 771,\n",
       " 'wings': 772,\n",
       " 'poodle': 773,\n",
       " 'neck': 774,\n",
       " 'rolling': 775,\n",
       " 'bandanna': 776,\n",
       " 'digging': 777,\n",
       " 'races': 778,\n",
       " 'wrestler': 779,\n",
       " 'hula': 780,\n",
       " 'lit': 781,\n",
       " 'hikers': 782,\n",
       " 'atv': 783,\n",
       " 'handstand': 784,\n",
       " 'pulled': 785,\n",
       " 'filled': 786,\n",
       " 'softball': 787,\n",
       " 'gloves': 788,\n",
       " 'school': 789,\n",
       " 'rapids': 790,\n",
       " 'curly': 791,\n",
       " 'cricket': 792,\n",
       " 'lights': 793,\n",
       " 'african': 794,\n",
       " 'grinding': 795,\n",
       " 'signs': 796,\n",
       " 'opposing': 797,\n",
       " 'having': 798,\n",
       " 'outstretched': 799,\n",
       " 'spray': 800,\n",
       " 'creek': 801,\n",
       " 'lap': 802,\n",
       " 'carnival': 803,\n",
       " 'matching': 804,\n",
       " 'mother': 805,\n",
       " 'third': 806,\n",
       " 'jeep': 807,\n",
       " 'hay': 808,\n",
       " 'talk': 809,\n",
       " 'shooting': 810,\n",
       " 'thrown': 811,\n",
       " 'paddling': 812,\n",
       " 'indoor': 813,\n",
       " 'deck': 814,\n",
       " 'mouths': 815,\n",
       " 'brightly': 816,\n",
       " 'giving': 817,\n",
       " 'photograph': 818,\n",
       " 'chase': 819,\n",
       " 'base': 820,\n",
       " 'try': 821,\n",
       " 'stadium': 822,\n",
       " 'licking': 823,\n",
       " 'plate': 824,\n",
       " 'appears': 825,\n",
       " 'skates': 826,\n",
       " 'christmas': 827,\n",
       " 'market': 828,\n",
       " 'giant': 829,\n",
       " 'tackle': 830,\n",
       " 'wheelchair': 831,\n",
       " 'smoke': 832,\n",
       " 'runner': 833,\n",
       " 'different': 834,\n",
       " 'lies': 835,\n",
       " 'seen': 836,\n",
       " 'paddle': 837,\n",
       " 'terrain': 838,\n",
       " 'atop': 839,\n",
       " 'floating': 840,\n",
       " 'backpacks': 841,\n",
       " 'hitting': 842,\n",
       " 'animals': 843,\n",
       " 'alongside': 844,\n",
       " 'funny': 845,\n",
       " 'reaching': 846,\n",
       " 'balancing': 847,\n",
       " 'gather': 848,\n",
       " 'raises': 849,\n",
       " 'singing': 850,\n",
       " 'basket': 851,\n",
       " 'spotted': 852,\n",
       " 'moving': 853,\n",
       " 'newspaper': 854,\n",
       " 'putting': 855,\n",
       " 'plants': 856,\n",
       " 'ear': 857,\n",
       " 'bushes': 858,\n",
       " 'competing': 859,\n",
       " 'enjoys': 860,\n",
       " 'fly': 861,\n",
       " 'professional': 862,\n",
       " 'larger': 863,\n",
       " 'rollerblades': 864,\n",
       " 'riders': 865,\n",
       " 'before': 866,\n",
       " 'falls': 867,\n",
       " 'shakes': 868,\n",
       " 'jumped': 869,\n",
       " 'seven': 870,\n",
       " 'hang': 871,\n",
       " 'hot': 872,\n",
       " 'safety': 873,\n",
       " 'shows': 874,\n",
       " 'handrail': 875,\n",
       " 'audience': 876,\n",
       " 'station': 877,\n",
       " 'step': 878,\n",
       " 'bikers': 879,\n",
       " 'straw': 880,\n",
       " 'hooded': 881,\n",
       " 'makeup': 882,\n",
       " 'splashed': 883,\n",
       " 'playfully': 884,\n",
       " 'formation': 885,\n",
       " 'preparing': 886,\n",
       " 'backs': 887,\n",
       " 'multicolored': 888,\n",
       " 'camouflage': 889,\n",
       " 'surfs': 890,\n",
       " 'music': 891,\n",
       " 'indoors': 892,\n",
       " 'teenagers': 893,\n",
       " 'duck': 894,\n",
       " 'muzzled': 895,\n",
       " 'cone': 896,\n",
       " 'blows': 897,\n",
       " 'round': 898,\n",
       " 'terrier': 899,\n",
       " 'overalls': 900,\n",
       " 'climbers': 901,\n",
       " 'row': 902,\n",
       " 'lined': 903,\n",
       " 'pull': 904,\n",
       " 'alone': 905,\n",
       " 'gun': 906,\n",
       " 'leap': 907,\n",
       " 'shaggy': 908,\n",
       " 'landing': 909,\n",
       " 'pipe': 910,\n",
       " 'writing': 911,\n",
       " 'gives': 912,\n",
       " 'block': 913,\n",
       " 'hoodie': 914,\n",
       " 'cloth': 915,\n",
       " 'chain': 916,\n",
       " 'coats': 917,\n",
       " 'himself': 918,\n",
       " 'follows': 919,\n",
       " 'owner': 920,\n",
       " 'muzzle': 921,\n",
       " 'home': 922,\n",
       " 'spinning': 923,\n",
       " 'friend': 924,\n",
       " 'barrier': 925,\n",
       " 'laugh': 926,\n",
       " 'doorway': 927,\n",
       " 'passing': 928,\n",
       " 'instruments': 929,\n",
       " 'flight': 930,\n",
       " 'break': 931,\n",
       " 'construction': 932,\n",
       " 'puts': 933,\n",
       " 'quickly': 934,\n",
       " 'finger': 935,\n",
       " 'laughs': 936,\n",
       " 'motorcycles': 937,\n",
       " 'naked': 938,\n",
       " 'tug': 939,\n",
       " 'bite': 940,\n",
       " 'motorbike': 941,\n",
       " 'says': 942,\n",
       " 'foreground': 943,\n",
       " 'referee': 944,\n",
       " 'these': 945,\n",
       " 'roller': 946,\n",
       " 'trunk': 947,\n",
       " 'pulls': 948,\n",
       " 'shoulders': 949,\n",
       " 'fur': 950,\n",
       " 'fair': 951,\n",
       " 'covering': 952,\n",
       " 'mound': 953,\n",
       " 'opposite': 954,\n",
       " 'sea': 955,\n",
       " 'spiderman': 956,\n",
       " 'pigeons': 957,\n",
       " 'violin': 958,\n",
       " 'uses': 959,\n",
       " 'cut': 960,\n",
       " 'skiers': 961,\n",
       " 'collie': 962,\n",
       " 'stop': 963,\n",
       " 'wagon': 964,\n",
       " 'bank': 965,\n",
       " 'computer': 966,\n",
       " 'float': 967,\n",
       " 'peace': 968,\n",
       " 'tie': 969,\n",
       " 'rubber': 970,\n",
       " 'denim': 971,\n",
       " 'fetch': 972,\n",
       " 'pack': 973,\n",
       " 'martial': 974,\n",
       " 'gate': 975,\n",
       " 'counter': 976,\n",
       " 'kite': 977,\n",
       " 'wheelie': 978,\n",
       " 'staircase': 979,\n",
       " 'caught': 980,\n",
       " 'range': 981,\n",
       " 'barking': 982,\n",
       " 'shadow': 983,\n",
       " 'ducks': 984,\n",
       " 'clown': 985,\n",
       " 'spots': 986,\n",
       " 'frozen': 987,\n",
       " 'half': 988,\n",
       " 'reaches': 989,\n",
       " 'kneeling': 990,\n",
       " 'crouches': 991,\n",
       " 'jean': 992,\n",
       " 'tracks': 993,\n",
       " 'cold': 994,\n",
       " 'frame': 995,\n",
       " 'enjoying': 996,\n",
       " 'skater': 997,\n",
       " 'crashing': 998,\n",
       " 'tires': 999,\n",
       " 'kneels': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_text = '/tf/notebooks/captioning_image/Flickr8k_text'\n",
    "filename = dataset_text + '/Flickr8k.token.txt'\n",
    "descrip = all_img_captions(filename)\n",
    "\n",
    "def get_max_length(descriptions):\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    return max(len(d.split()) for d in desc_list)\n",
    "\n",
    "max_length = get_max_length(descrip)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generator, used by model.fit_generator()\n",
    "def data_generator(descriptions, features, tokenizer, max_length):\n",
    "    while 1:\n",
    "        for key, description_list in descriptions.items():\n",
    "            feature = features[key][0]\n",
    "            input_image, input_sequence, output_word = create_sequences(\n",
    "                tokenizer, \n",
    "                max_length, \n",
    "                description_list, \n",
    "                feature\n",
    "            )\n",
    "            yield ([input_image, input_sequence], output_word)\n",
    "\n",
    "def create_sequences(tokenizer, max_length, desc_list, feature):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    # walk through each description for the image\n",
    "    for desc in desc_list:\n",
    "        # encode the sequence\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        # split one sequence into multiple X,y pairs\n",
    "        for i in range(1, len(seq)):\n",
    "            # split into input and output pair\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            # pad input sequence\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "            # encode output sequence\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            # store\n",
    "            X1.append(feature)\n",
    "            X2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "# Shape of the input and output\n",
    "# [a,b],c = next(data_generator(train_descriptions, features, tokenizer, max_length))\n",
    "# a.shape, b.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "\n",
    "def define_model(vocab_size, max_length):\n",
    "    # features from the CNN model squeezed from 2048 to 256 nodes\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "    # LSTM sequence model\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "    # Merging both models\n",
    "    decoder1 = add([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "    # tie it together [image, seq] [word]\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    # summarize model\n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  6000\n",
      "Descriptions: train= 6000\n",
      "Photos: train= 6000\n",
      "Vocabulary Size: 7577\n",
      "Description Length:  38\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 38)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 38, 256)      1939712     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 2048)         0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 38, 256)      0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          524544      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 256)          525312      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256)          0           dense_9[0][0]                    \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          65792       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 7577)         1947289     dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,002,649\n",
      "Trainable params: 5,002,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "6000/6000 [==============================] - 414s 67ms/step - loss: 4.5927\n",
      "6000/6000 [==============================] - 403s 67ms/step - loss: 3.8405\n",
      "6000/6000 [==============================] - 402s 67ms/step - loss: 3.5780\n",
      "6000/6000 [==============================] - 403s 67ms/step - loss: 3.4074\n",
      "6000/6000 [==============================] - 404s 67ms/step - loss: 3.2875\n",
      "6000/6000 [==============================] - 405s 67ms/step - loss: 3.1972\n",
      "6000/6000 [==============================] - 403s 67ms/step - loss: 3.1251\n",
      "6000/6000 [==============================] - 403s 67ms/step - loss: 3.0642\n",
      "6000/6000 [==============================] - 403s 67ms/step - loss: 3.0132\n",
      "6000/6000 [==============================] - 404s 67ms/step - loss: 2.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "# train our model\n",
    "print('Dataset: ', len(train_imgs))\n",
    "print('Descriptions: train=', len(train_descriptions))\n",
    "print('Photos: train=', len(train_features))\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Description Length: ', max_length)\n",
    "model = define_model(vocab_size, max_length)\n",
    "epochs = 10\n",
    "steps = len(train_descriptions)\n",
    "# making a directory models to save our models\n",
    "# os.mkdir(\"models\")\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
    "    model.fit_generator(generator, epochs=1, steps_per_epoch= steps, verbose=1)\n",
    "model.save(\"models/model_caption_generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filename, model):\n",
    "        try:\n",
    "            image = Image.open(filename)\n",
    "        except:\n",
    "            print(\"ERROR: Couldn't open image! Make sure the image path and extension is correct\")\n",
    "        image = image.resize((224,224))\n",
    "        image = np.array(image)\n",
    "        # for images that has 4 channels, we convert them into 3 channels\n",
    "        if image.shape[2] == 4: \n",
    "            image = image[..., :3]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image/127.5\n",
    "        image = image - 1.0\n",
    "        feature = model.predict(image)\n",
    "        return feature\n",
    "\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "         if index == integer:\n",
    "             return word\n",
    "    return None\n",
    "\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    in_text = 'start'\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        pred = model.predict([photo,sequence], verbose=0)\n",
    "        pred = np.argmax(pred)\n",
    "        word = word_for_id(pred, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'end':\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'Flicker8k_Dataset/111537222_07e56d5a30.jpg'\n",
    "max_length = 38\n",
    "tokenizer = load(open(\"tokenizer.p\",\"rb\"))\n",
    "model = load_model('models/model_caption_generator.h5')\n",
    "xception_model = ResNet50(include_top=False, pooling='avg')\n",
    "img_path = '19026518_a48207c980.jpg'\n",
    "photo = extract_features(img_path, xception_model)\n",
    "img = Image.open(img_path)\n",
    "\n",
    "description = generate_desc(model, tokenizer, photo, max_length)\n",
    "print(\"\\n\\n\")\n",
    "print(description)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
